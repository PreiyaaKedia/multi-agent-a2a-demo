"""
Multi-agent routing application with Azure AI Agents integration.

This application provides a Gradio interface for interacting with a routing agent
that uses Azure AI Agents for core functionality and delegates tasks to remote agents.
"""

import asyncio
import os
import traceback
from collections.abc import AsyncIterator
from pprint import pformat

import gradio as gr

from routing_agent import RoutingAgent

APP_NAME = "azure_routing_app"
USER_ID = "default_user"
SESSION_ID = "default_session"

# Global routing agent instance
ROUTING_AGENT: RoutingAgent = None


async def get_response_from_agent(
    message: str,
    history: list[gr.ChatMessage],
) -> AsyncIterator[gr.ChatMessage]:
    """Get response from Azure AI Foundry Agent routing by A2A and Semantic Kernel."""
    global ROUTING_AGENT
    
    if not ROUTING_AGENT:
        yield gr.ChatMessage(
            role="assistant",
            content="‚ùå **Error**: Routing agent not initialized. Please restart the application.",
        )
        return
    
    try:
        # Debug: Check what type of message we're receiving
        print(f"DEBUG: Received message type: {type(message)}")
        print(f"DEBUG: Message content: {message}")
        
        # Handle different message types from multimodal ChatInterface
        if isinstance(message, str):
            user_text = message
        elif isinstance(message, dict):
            # If it's a dict, extract text content
            user_text = message.get('text', str(message))
        elif isinstance(message, list):
            # If it's a list, extract text parts
            text_parts = [item for item in message if isinstance(item, str)]
            user_text = ' '.join(text_parts) if text_parts else str(message)
        else:
            # Fallback: convert to string
            user_text = str(message)
        
        # Show that we're processing the request
        yield gr.ChatMessage(
            role="assistant",
            content="ü§î **Processing your request...**",
        )
        
        # Process the message through Azure AI Agent
        response = await ROUTING_AGENT.process_user_message(user_text)
        
        # Yield the final response
        if response:
            # Debug: Check what we received
            print(f"DEBUG: Response type: {type(response)}")
            print(f"DEBUG: Response content: {response}")
            
            # Check if response is a file (image) artifact
            if isinstance(response, dict) and response.get("type") == "file":
                import base64
                import tempfile
                import os
                from datetime import datetime
                
                try:
                    print("DEBUG: Processing file artifact...")
                    # Decode the base64 image data
                    image_bytes = base64.b64decode(response["file_data"])
                    agent_name = response.get("agent_name", "Analytics Agent")
                    
                    # Create charts directory for persistent storage
                    charts_dir = os.path.join(os.getcwd(), "generated_charts")
                    os.makedirs(charts_dir, exist_ok=True)
                    
                    # Generate filename with timestamp and description
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    chart_filename = f"chart_{timestamp}.png"
                    persistent_path = os.path.join(charts_dir, chart_filename)
                    
                    # Save to persistent location
                    with open(persistent_path, 'wb') as f:
                        f.write(image_bytes)
                    
                    # Also save to temporary file for Gradio display
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp:
                        tmp.write(image_bytes)
                        temp_path = tmp.name
                    
                    print(f"Chart saved to persistent location: {persistent_path}")
                    print(f"Chart saved to temp location for display: {temp_path}")
                    
                    # Return text message with file location info
                    yield gr.ChatMessage(
                        role="assistant",
                        content=f"üé® **Chart generated by {agent_name}**\n\nüìÅ **Saved to**: `{persistent_path}`"
                    )

                    await asyncio.sleep(0.5)  # Small delay to ensure message order
                    
                    # Return the image using gr.Image component
                    yield gr.ChatMessage(
                        role="assistant",
                        content=gr.Image(value=temp_path, show_label=False)
                    )
                    
                except Exception as e:
                    print(f"Error processing image response: {e}")
                    import traceback
                    traceback.print_exc()
                    yield gr.ChatMessage(
                        role="assistant",
                        content=f"üìä **Chart generated by {response.get('agent_name', 'Analytics Agent')}** but there was an error displaying it: {str(e)}"
                    )
            else:
                # Regular text response
                yield gr.ChatMessage(
                    role="assistant", 
                    content=response
                )
        else:
            yield gr.ChatMessage(
                role="assistant",
                content="‚ùå **Error**: No response received from the agent.",
            )
            
    except Exception as e:
        print(f"Error in get_response_from_agent (Type: {type(e)}): {e}")
        traceback.print_exc()
        yield gr.ChatMessage(
            role="assistant",
            content=f"‚ùå **An error occurred**: {str(e)}\n\nPlease check the server logs for details.",
        )


async def initialize_routing_agent():
    """Initialize the Azure AI routing agent."""
    global ROUTING_AGENT
    
    try:
        print("Initializing Azure AI routing agent...")
        
        # Create the routing agent with remote agent addresses
        ROUTING_AGENT = await RoutingAgent.create(
            remote_agent_addresses=[
                # os.getenv('PLAYWRIGHT_AGENT_URL', 'http://localhost:10001'),
                os.getenv('TOOL_AGENT_URL', 'https://dev-toolagent-web.azurewebsites.net'),
                os.getenv('CHARTGENERATION_CREWAI_AGENT_URL', 'http://localhost:10011'),
                os.getenv('REIMBURSEMENT_AGENT_URL', 'http://localhost:10005'),
            ]
        )
        
        # Create the Azure AI agent
        azure_agent = ROUTING_AGENT.create_agent()
        print(f"Azure AI routing agent initialized successfully with ID: {azure_agent.id}")
        
    except Exception as e:
        print(f"Failed to initialize routing agent: {e}")
        traceback.print_exc()
        raise


async def cleanup_routing_agent():
    """Clean up the routing agent resources."""
    global ROUTING_AGENT
    
    if ROUTING_AGENT:
        try:
            ROUTING_AGENT.cleanup()
            print("Routing agent cleaned up successfully.")
        except Exception as e:
            print(f"Error during cleanup: {e}")
        finally:
            ROUTING_AGENT = None


async def main():
    """Main gradio app with Azure AI Agents integration."""
    
    # Check required environment variables
    required_env_vars = [
        "AZURE_AI_PROJECT_ENDPOINT",
        "model"
    ]
    
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    if missing_vars:
        print(f"‚ùå Missing required environment variables: {', '.join(missing_vars)}")
        print("Please set these environment variables before running the application.")
        return
    
    # Initialize the routing agent
    await initialize_routing_agent()

    try:
        with gr.Blocks(theme=gr.themes.Ocean(), title="Azure AI Routing Agent") as demo:
            # Header section
            gr.Markdown("""
            # ü§ñ Azure AI Routing Agent
            
            This assistant uses Azure AI Agents to help you to use playwright and some dev tools.
            The agent intelligently routes your requests to specialized remote agents for optimal assistance.
            """)
            
            # Display agent status
            if ROUTING_AGENT and ROUTING_AGENT.azure_agent:
                gr.Markdown(f"""
                ### üìä Agent Status
                - **Azure AI Agent ID**: `{ROUTING_AGENT.azure_agent.id}`
                - **Thread ID**: `{ROUTING_AGENT.current_thread.id if ROUTING_AGENT.current_thread else 'Not created'}`
                - **Available Remote Agents**: {len(ROUTING_AGENT.remote_agent_connections)}
                """)
            
            # Chat interface with file uploads enabled
            with gr.Row():
                with gr.Column(scale=1):
                    gr.ChatInterface(
                        get_response_from_agent,
                        title="üí¨ Chat with Azure AI Routing Agent",
                        description="Give me a message, I will help you to browse the web, clone repo, or open it with VSCode and VSCode Insiders",
                        examples=[
                            "Clone repo https://github.com/kinfey/mcpdemo1",
                            "Go to github.com/kinfey",
                            "Open {path} with VSCode or VSCode Insiders",
                            "Generate a chart of revenue: Jan,$1000 Feb,$2000 Mar,$1500"
                        ],
                        multimodal=True
                    )
            
            # Footer
            gr.Markdown("""
            ---
            **Powered by**: Azure AI Agents | **A2A Framework**: Multi-Agent Routing System with Semantic Kernel and A2A
            """)

        print("Launching Gradio interface...")
        demo.queue().launch(
            server_name="0.0.0.0",
            server_port=8083,
            share=True
        )
        
    except Exception as e:
        print(f"Error in main application: {e}")
        traceback.print_exc()
    finally:
        print("Shutting down application...")
        await cleanup_routing_agent()
        print("Gradio application has been shut down.")

if __name__ == "__main__":
    asyncio.run(main())